# Programación Python para Data Science (UOC) - Unidad 5

Código de la Unidad 5 de la asignatura Fundamentos de Programación.    

**Borja Villena Pardo**    

Archivo de entrega ***`prog_datasci_8_vis_entrega.ipynb`***    
Ejecutar ***`prog_datasci_8_vis_entrega.ipynb`*** en entorno **Jupyter NoteBook, Anaconda Navigator o Google Colab**.    

Este repositorio contiene:

* Un notebook con explicaciones teóricas (`prog_datasci_5_api.ipynb`):

veremos ejemplos de adquisición
de datos de Internet con tres métodos diferentes:    

1º - descarga directa    
2º - petición a APIs de terceros    
3º - web crawling    

Por lo que respeta a la interacción con APIs de terceros, repasaremos dos alternativas, la construcción
manual de las peticiones HTTP y el uso de librerías Python.    

Con relación al web crawling, veremos cómo utilizar la librería Scrapy (https://scrapy.org/) para construir un
pequeño web crawler que capture datos de nuestro interés.    

* Un notebook con la PAC5 de la asignatura (`prog_datasci_5_api_entrega.ipynb`).
* Un notebook con ejercicios resueltos para practicar los conceptos explicados (`prog_datasci_5_api_exercicisResueltos.ipynb`).
* Un notebook con un tutorial de creación de expresiones xpath para programar los *parsers* de *crawlers* (`prog_datasci_5_api_tutorial_scrapy.ipynb`):

veremos los conceptos básicos de páginas web que nos ayudaran a desarrollar
crawlers con scrapy, en especial, a desarrollar el parser, que es la parte del crawler que selecciona,
de cada página, qué datos nos interesa guardar.   

Una vez identificado el código HTML que nos interesa,
veremos cómo podemos derivar las expresiones xpath para seleccionarlo, además de cómo podemos
refinar estas expresiones y probarlas.





